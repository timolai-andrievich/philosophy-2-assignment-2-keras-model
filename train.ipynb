{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timolai-andrievich/philosophy-2-assignment-2-keras-model/blob/main/train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import pathlib\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 8\n",
    "BATCH_SIZE = 256\n",
    "WEIGHTED_MSE_ZERO_COEFFICIENT = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in Google Colab\n",
    "%pip install pretty_midi --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the [Maestro](https://magenta.tensorflow.org/datasets/maestro) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'maestro-v2.0.0-midi.zip',\n",
    "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_notes(pretty_midi_object: pretty_midi.PrettyMIDI) -> np.ndarray:\n",
    "    \"\"\"Group the notes in the midi file by the beats they were played in.\n",
    "\n",
    "    Args:\n",
    "        pretty_midi_object (pretty_midi.PrettyMIDI): The pretty midi object\n",
    "            containing the information about the melody.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The numpy array containing the bitmap of the notes\n",
    "            that were played in a certaing beat of the melody.\n",
    "    \"\"\"    \n",
    "    result = np.zeros((len(pretty_midi_object.get_beats()) - 1, 128), np.int8)\n",
    "    beats = np.array(pretty_midi_object.get_beats())\n",
    "    for note in pretty_midi_object.instruments[0].notes:\n",
    "        start_beat = np.searchsorted(beats, note.start, 'right')\n",
    "        end_beat = np.searchsorted(beats, note.end, 'left')\n",
    "        result[start_beat:end_beat, note.pitch] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the notes from the dataset into one tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.zeros((0, 128), np.int8)\n",
    "for file in tqdm.tqdm(glob.glob('data/*/*/*.midi')):\n",
    "    file_notes = group_notes(pretty_midi.PrettyMIDI(file))\n",
    "    notes = np.concatenate([notes, file_notes])\n",
    "notes_in_tensor = tf.convert_to_tensor(notes, tf.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(idx: int) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    return notes_in_tensor[idx:idx+SEQ_LEN], notes_in_tensor[idx+SEQ_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = list(range(notes.shape[0] - SEQ_LEN - 1))\n",
    "train_idx, test_idx = train_test_split(indexes, test_size=.1, random_state=42)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_idx).map(load_index).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_idx).map(load_index).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `weighted_mse` loss function: \n",
    "$$ L(y, \\hat{y}) = \\lambda_{0}\\mathop{\\mathbb{E}}\\limits_{i=0}^{128}(y_i - \\hat{y}_i)^2 \\mathbb{C}_i^0 + \\\\ \n",
    "\\mathop{\\mathbb{E}}\\limits_{i=0}^{128}(y_i - \\hat{y}_i)^2 \\mathbb{C}_i^1 $$\n",
    "Where $\\mathbb{C}^0_i$ denotes if there is no note with pitch $i$ in the beat, and $\\mathbb{C}^1_i$ denotes if there is a note with pitch $i$ in the beat, $y$ denote real values, $\\hat{y}$ denote predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    loss_1 = (y_true - y_pred) ** 2 * y_true\n",
    "    loss_0 = (y_true - y_pred) ** 2 * (1 - y_true)\n",
    "    return tf.reduce_mean(loss_0 * WEIGHTED_MSE_ZERO_COEFFICIENT + loss_1, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topology of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(256),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss=weighted_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('net.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee6ef56facda7503055c4941e2c2083c4bcc9ecb08a66ac58f56d3b05ea5e5fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
